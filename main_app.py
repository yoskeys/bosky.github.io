import streamlit as st

# ã‚ˆã™ããƒ¼ã®éƒ¨å±‹é¢¨ã®ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’AIã‚¢ãƒ—ãƒªã«ã‚‚è¡¨ç¤º
st.markdown("""
    <style>
        .yoskey-header {
            text-align: center;
            color: #333;
            background-color: #f0f2f6;
            padding: 10px;
            border-radius: 10px;
            margin-bottom: 20px;
        }
    </style>
    <div class="yoskey-header">
        <h2>ã‚ˆã™ããƒ¼ã®éƒ¨å±‹ã®å¤©æ°—äºˆå ±</h2>
    </div>
    """, unsafe_allow_html=True)

# --- ã“ã“ã‹ã‚‰ä¸‹ã«ã€ã“ã‚Œã¾ã§ã®äºˆæ¸¬ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’ç¶šã‘ã‚‹ ---

import streamlit as st
import datetime
import pandas as pd
import requests
from bs4 import BeautifulSoup
import numpy as np
from sklearn.linear_model import LinearRegression
import time

# --- ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="å¤©æ°—äºˆå ±")
st.title("ğŸŒ¡ï¸ 7æ—¥é–“ãƒˆãƒ¬ãƒ³ãƒ‰äºˆå ±")
st.write("ç›´è¿‘7æ—¥é–“ã®å®Ÿæ³å€¤ã‚’è‡ªå‹•å–å¾—ã—ã€éå»æ•°å¹´ã®åŒæ™‚æœŸã®å‚¾å‘ã‚’ã€é‡ã¿ä»˜ã‘å­¦ç¿’ã€ã—ã¦ä»Šæ—¥ã‚’äºˆæ¸¬ã—ã¾ã™ã€‚")

# --- è¨­å®šï¼šå–å¾—ã™ã‚‹åœ°ç‚¹ ---
STATIONS = {
    'tokyo': {'prec_no': 44, 'block_no': 47662},
    'kofu': {'prec_no': 49, 'block_no': 47638}
}

# --- 1. æ°—è±¡åºã‹ã‚‰1æ—¥åˆ†ã®ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã™ã‚‹é–¢æ•° ---
def fetch_daily_data(date, prec_no, block_no):
    url = f"https://www.data.jma.go.jp/obd/stats/etrn/view/hourly_s1.php?prec_no={prec_no}&block_no={block_no}&year={date.year}&month={date.month}&day={date.day}&view="
    try:
        r = requests.get(url, timeout=10)
        r.encoding = r.apparent_encoding
        soup = BeautifulSoup(r.text, 'html.parser')
        rows = soup.find_all('tr', class_='mtx')
        data = []
        for row in rows[2:]:
            cols = row.find_all('td')
            data.append([col.text for col in cols])
        df = pd.DataFrame(data)
        # æ•°å€¤å¤‰æ›ï¼ˆæ°—æ¸©4, æ¹¿åº¦7, æ°—åœ§2, é™æ°´3, æ—¥ç…§12ï¼‰
        for col in [4, 7, 2, 3, 12]:
            df[col] = pd.to_numeric(df[col], errors='coerce')
        
        return {
            'temp_mean': df[4].mean(), 'temp_max': df[4].max(), 'temp_min': df[4].min(),
            'hum': df[7].mean(), 'press': df[2].mean(), 'precip': df[3].sum(), 'sun': df[12].sum()
        }
    except:
        return None

# --- 2. å­£ç¯€ã®é‡ã¿ã‚’è¨ˆç®—ã™ã‚‹é–¢æ•° ---
def calculate_seasonal_weights(data_months, current_month):
    # æœˆã®è·é›¢ã‚’è¨ˆç®—ï¼ˆ12æœˆã¨1æœˆã¯è·é›¢1ï¼‰
    diff = np.abs(data_months - current_month)
    diff = np.where(diff > 6, 12 - diff, diff)
    # è·é›¢ãŒè¿‘ã„ã»ã©é‡ã¿ã‚’å¤§ããï¼ˆ1.0ã€œ0.14ã®ç¯„å›²ï¼‰
    return 1.0 / (diff + 1)

# --- ãƒ¡ã‚¤ãƒ³å‡¦ç† ---
if st.button('æœ€æ–°ã®ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’è§£æã—ã¦äºˆæ¸¬é–‹å§‹'):
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    try:
        # STEP 1: ç›´è¿‘7æ—¥é–“ã®å®Ÿæ³å€¤ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å–å¾—
        recent_input_values = []
        # 1æ—¥å‰ã‹ã‚‰7æ—¥å‰ã¾ã§é¡ã‚‹
        target_dates = [(datetime.date.today() - datetime.timedelta(days=i)) for i in range(1, 8)]
        
        for i, date in enumerate(target_dates):
            status_text.text(f"ğŸ“¡ æ°—è±¡åºã‹ã‚‰å®Ÿæ³ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­: {date} ({i+1}/7æ—¥åˆ†)")
            day_data = []
            for name, ids in STATIONS.items():
                res = fetch_daily_data(date, ids['prec_no'], ids['block_no'])
                if res:
                    day_data.extend([res['temp_mean'], res['temp_max'], res['temp_min'], res['hum'], res['press'], res['precip'], res['sun']])
                else:
                    raise Exception(f"{date}ã®ãƒ‡ãƒ¼ã‚¿å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
            recent_input_values.extend(day_data)
            progress_bar.progress((i + 1) / 7)
            time.sleep(0.2)

        # STEP 2: å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™ï¼ˆãƒ©ã‚°ç‰¹å¾´é‡ã®ä½œæˆï¼‰
        status_text.text("ğŸ§  ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å­£ç¯€ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’ä¸­...")
        df_all = pd.read_csv('weather_database.csv')
        df_all['date'] = pd.to_datetime(df_all['date'])
        df_all = df_all.sort_values('date')

        # ç‰¹å¾´é‡ï¼ˆãƒ’ãƒ³ãƒˆï¼‰ã®åˆ—åãƒªã‚¹ãƒˆã‚’ä½œæˆ
        features = []
        base_cols = ['temp_mean', 'temp_max', 'temp_min', 'hum', 'press', 'precip', 'sun']
        for lag in range(1, 8):
            for st_name in STATIONS.keys():
                for col in base_cols:
                    col_name = f'lag{lag}_{st_name}_{col}'
                    df_all[col_name] = df_all[f'{st_name}_{col}'].shift(lag)
                    features.append(col_name)

        # æ¬ æå€¤ï¼ˆæœ€åˆã®7æ—¥åˆ†ï¼‰ã‚’å‰Šé™¤
        df_ml = df_all.dropna().copy()

        # STEP 3: å­£ç¯€ã®é‡ã¿ä»˜ã‘å­¦ç¿’
        current_month = datetime.date.today().month
        data_months = df_ml['date'].dt.month.values
        weights = calculate_seasonal_weights(data_months, current_month)

        # ä»Šæ—¥ã®äºˆæ¸¬ç”¨å…¥åŠ›ãƒ‡ãƒ¼ã‚¿
        input_df = pd.DataFrame([recent_input_values], columns=features)

        # å­¦ç¿’ã¨äºˆæ¸¬
        final_results = {}
        for key, t_col in {'max': 'tokyo_temp_max', 'min': 'tokyo_temp_min'}.items():
            model = LinearRegression()
            model.fit(df_ml[features], df_ml[t_col], sample_weight=weights)
            final_results[key] = model.predict(input_df)[0]

        # STEP 4: çµæœè¡¨ç¤º
        status_text.empty()
        st.success(f"è§£æå®Œäº†ï¼ ä»Šã®æ™‚æœŸï¼ˆ{current_month}æœˆï¼‰ã«æœ€é©åŒ–ã•ã‚ŒãŸäºˆæ¸¬ã§ã™ã€‚")
        
        col1, col2 = st.columns(2)
        col1.metric("äºˆæƒ³æœ€é«˜æ°—æ¸©", f"{final_results['max']:.1f} â„ƒ")
        col2.metric("äºˆæƒ³æœ€ä½æ°—æ¸©", f"{final_results['min']:.1f} â„ƒ")
        
        with st.expander("è§£æã®è©³ç´°ã‚’ç¢ºèª"):
            st.write(f"å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {len(df_ml)}ä»¶")
            st.write("ä½¿ç”¨ã—ãŸãƒ’ãƒ³ãƒˆ: ç›´è¿‘7æ—¥é–“ã®æ°—è±¡æ¨ç§»ï¼ˆè¨ˆ98é …ç›®ï¼‰")
            st.write("é‡ã¿ä»˜ã‘: ç¾åœ¨ã®æœˆã¨ã®è¿‘ã•ã«å¿œã˜ã¦ãƒ‡ãƒ¼ã‚¿ã®é‡è¦åº¦ã‚’èª¿æ•´æ¸ˆã¿")

    except Exception as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")